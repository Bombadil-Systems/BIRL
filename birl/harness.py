#!/usr/bin/env python3
"""
BIRL Test Harness

Generates a battery of test artifacts using every forge operation,
then provides a structured framework for testing them against:

1. AV/EDR detection (VirusTotal, Windows Defender, ClamAV)
2. CDR tools (Votiro, OPSWAT, Glasswall, etc.)
3. File upload validators (web apps, email gateways)
4. Manual verification (does the artifact actually work as intended)

Usage:
    birl-harness generate [--output-dir ./harness_output]
    birl-harness verify <artifact_dir>
    birl-harness report <artifact_dir>

Each artifact is generated with a manifest (JSON) describing:
- What it is
- What contexts it should satisfy
- What the expected behavior is under each test category
- Hash for tracking through external tools
"""

from __future__ import annotations

import argparse
import hashlib
import json
import os
import struct
import sys
import time
import zlib
import zipfile
import io
import shutil
from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path
from typing import Any, Optional

# Ensure birl is importable
birl_root = Path(__file__).resolve().parent.parent
if str(birl_root) not in sys.path:
    sys.path.insert(0, str(birl_root))

from birl import World, Runtime, compile_birl
from birl.forge import PolyglotForge, ROPForge, StripForge, WrapForge
from birl.residue import ResidueCalculator

try:
    from birl.contexts.production import (
        PEProductionContext,
        x86ProductionContext,
        PNGProductionContext,
        ZIPProductionContext,
        ELFProductionContext,
    )
    PRODUCTION = True
except ImportError:
    PRODUCTION = False

from birl.contexts import (
    PE_Context, ELF_Context, ZIP_Context,
    PNG_Context, UTF8_Context, x86_Context,
)


# ============================================================================
# Artifact Definition
# ============================================================================

@dataclass
class ArtifactSpec:
    """Defines a test artifact and its expected behavior."""
    id: str
    name: str
    category: str  # polyglot, stripped, injected, wrapped, rop
    description: str
    data: bytes = b""
    filename: str = ""
    # What contexts should the artifact satisfy
    expected_contexts: list[str] = field(default_factory=list)
    # Expected behavior
    expectations: dict[str, str] = field(default_factory=dict)
    # Generation metadata
    metadata: dict[str, Any] = field(default_factory=dict)
    # Forge result details
    forge_details: dict[str, Any] = field(default_factory=dict)

    @property
    def sha256(self) -> str:
        return hashlib.sha256(self.data).hexdigest()

    @property
    def md5(self) -> str:
        return hashlib.md5(self.data).hexdigest()

    def to_manifest(self) -> dict:
        return {
            "id": self.id,
            "name": self.name,
            "category": self.category,
            "description": self.description,
            "filename": self.filename,
            "size": len(self.data),
            "sha256": self.sha256,
            "md5": self.md5,
            "expected_contexts": self.expected_contexts,
            "expectations": self.expectations,
            "metadata": self.metadata,
            "forge_details": self.forge_details,
        }


# ============================================================================
# Source Material Generators
# ============================================================================

def make_benign_png(width: int = 32, height: int = 32) -> bytes:
    """Generate a benign PNG image — solid blue square."""
    sig = b"\x89PNG\r\n\x1a\n"
    def chunk(ctype, cdata):
        length = struct.pack(">I", len(cdata))
        crc = struct.pack(">I", zlib.crc32(ctype + cdata) & 0xFFFFFFFF)
        return length + ctype + cdata + crc

    ihdr = chunk(b"IHDR", struct.pack(">IIBBBBB", width, height, 8, 2, 0, 0, 0))
    # Solid blue pixels
    raw = b""
    for _ in range(height):
        raw += b"\x00"  # filter: none
        raw += (b"\x00\x00\xff") * width  # blue RGB
    idat = chunk(b"IDAT", zlib.compress(raw))
    iend = chunk(b"IEND", b"")
    return sig + ihdr + idat + iend


def make_benign_zip() -> bytes:
    """Generate a benign ZIP with innocent content."""
    buf = io.BytesIO()
    with zipfile.ZipFile(buf, "w", zipfile.ZIP_DEFLATED) as zf:
        zf.writestr("readme.txt", "This is a test document.\nGenerated by BIRL Test Harness.\n")
        zf.writestr("data/config.json", json.dumps({"version": "1.0", "test": True}))
    return buf.getvalue()


def make_benign_text() -> bytes:
    """Generate benign text content."""
    return b"""BIRL Test Harness - Generated Document

This file was generated as part of a security testing battery.
It contains no malicious content. Its purpose is to verify how
security tools handle various file format constructions.

Lorem ipsum dolor sit amet, consectetur adipiscing elit.
Sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.
"""


def make_eicar() -> bytes:
    """EICAR test string — standard AV test payload.
    Every AV should detect this. It's the control sample."""
    return b"X5O!P%@AP[4\\PZX54(P^)7CC)7}$EICAR-STANDARD-ANTIVIRUS-TEST-FILE!$H+H*"


def make_marker_payload(tag: str = "BIRL") -> bytes:
    """A recognizable but inert marker payload."""
    return f"[{tag}:HARNESS:{int(time.time())}]".encode() + b"\x00" * 32


# ============================================================================
# Artifact Generators
# ============================================================================

class HarnessGenerator:
    """Generates the full battery of test artifacts."""

    def __init__(self):
        self._forge_poly = PolyglotForge()
        self._forge_strip = StripForge()
        self._forge_wrap = WrapForge()
        self._residue_calc = ResidueCalculator()

        if PRODUCTION:
            self._png_ctx = PNGProductionContext()
            self._zip_ctx = ZIPProductionContext()
        else:
            self._png_ctx = PNG_Context()
            self._zip_ctx = ZIP_Context()

    def generate_all(self) -> list[ArtifactSpec]:
        """Generate the complete artifact battery."""
        artifacts = []

        print("Generating test artifacts...")
        print()

        # --- Controls ---
        artifacts += self._generate_controls()

        # --- Polyglots ---
        artifacts += self._generate_polyglots()

        # --- Stripped (Veriduct) ---
        artifacts += self._generate_stripped()

        # --- Residue Injected ---
        artifacts += self._generate_injected()

        # --- Wrapped ---
        artifacts += self._generate_wrapped()

        # --- Nested / Layered ---
        artifacts += self._generate_layered()

        return artifacts

    def _generate_controls(self) -> list[ArtifactSpec]:
        """Control samples — known-good and known-bad."""
        print("  [1/6] Control samples...")
        artifacts = []

        # Clean PNG
        png = make_benign_png()
        artifacts.append(ArtifactSpec(
            id="CTRL-001", name="Clean PNG (32x32 blue)",
            category="control",
            description="Unmodified PNG image. Should pass all checks.",
            data=png, filename="clean_image.png",
            expected_contexts=["PNG"],
            expectations={
                "av": "PASS — no detection",
                "cdr": "PASS — sanitized normally or passed through",
                "upload": "PASS — valid image/png",
                "manual": "Opens as solid blue square in any image viewer",
            },
        ))

        # Clean ZIP
        zdata = make_benign_zip()
        artifacts.append(ArtifactSpec(
            id="CTRL-002", name="Clean ZIP",
            category="control",
            description="Standard ZIP archive with text files. Should pass all checks.",
            data=zdata, filename="clean_archive.zip",
            expected_contexts=["ZIP"],
            expectations={
                "av": "PASS — no detection",
                "cdr": "PASS — sanitized normally",
                "upload": "PASS — valid application/zip",
                "manual": "Extracts readme.txt and data/config.json",
            },
        ))

        # EICAR (positive control)
        eicar = make_eicar()
        artifacts.append(ArtifactSpec(
            id="CTRL-003", name="EICAR Test String",
            category="control",
            description="Standard AV test payload. Every AV MUST detect this.",
            data=eicar, filename="eicar_test.txt",
            expected_contexts=["UTF8"],
            expectations={
                "av": "DETECT — if AV misses EICAR, it's broken",
                "cdr": "BLOCK or STRIP",
                "upload": "BLOCK in security-aware systems",
                "manual": "Text file containing EICAR string",
            },
        ))

        return artifacts

    def _generate_polyglots(self) -> list[ArtifactSpec]:
        """Polyglot artifacts — files valid under multiple contexts."""
        print("  [2/6] Polyglots...")
        artifacts = []

        png = make_benign_png()
        zdata = make_benign_zip()

        # PNG + ZIP polyglot (append)
        result = self._forge_poly.append(png, self._png_ctx, zdata, self._zip_ctx)
        if result.success:
            artifacts.append(ArtifactSpec(
                id="POLY-001", name="PNG+ZIP Polyglot (append)",
                category="polyglot",
                description="Valid PNG with ZIP appended after IEND. "
                            "Image viewers see PNG. Archive tools see ZIP.",
                data=result.data, filename="image_archive.png",
                expected_contexts=["PNG", "ZIP"],
                expectations={
                    "av": "INTERESTING — most AV only parses one format",
                    "cdr": "KEY TEST — does CDR sanitize BOTH format layers?",
                    "upload": "May pass as image/png if validator only checks magic bytes",
                    "manual": "Opens as blue square in image viewer AND extracts as ZIP",
                },
                forge_details={
                    "png_coverage": result.validations.get("PNG", None) and f"{result.validations['PNG'].coverage:.1%}",
                    "zip_coverage": result.validations.get("ZIP", None) and f"{result.validations['ZIP'].coverage:.1%}",
                },
            ))

        # ZIP + PNG polyglot (reversed — ZIP primary)
        result2 = self._forge_poly.append(zdata, self._zip_ctx, png, self._png_ctx)
        if result2.success and result2.is_valid_polyglot:
            artifacts.append(ArtifactSpec(
                id="POLY-002", name="ZIP+PNG Polyglot (ZIP primary)",
                category="polyglot",
                description="ZIP with PNG appended. Tests whether tools "
                            "identify by magic bytes (PNG: 89504E47) or structure.",
                data=result2.data, filename="archive_image.zip",
                expected_contexts=["ZIP", "PNG"],
                expectations={
                    "av": "Tests format identification priority",
                    "cdr": "Which parser runs? ZIP or PNG?",
                    "upload": "Depends on whether validator checks header or extension",
                    "manual": "May work as ZIP; PNG detection depends on tool",
                },
            ))

        # PNG + EICAR-in-ZIP polyglot
        eicar_zip = io.BytesIO()
        with zipfile.ZipFile(eicar_zip, "w") as zf:
            zf.writestr("test.txt", make_eicar().decode("ascii"))
        eicar_zip_bytes = eicar_zip.getvalue()

        result3 = self._forge_poly.append(png, self._png_ctx, eicar_zip_bytes, self._zip_ctx)
        if result3.success:
            artifacts.append(ArtifactSpec(
                id="POLY-003", name="PNG+ZIP(EICAR) Polyglot",
                category="polyglot",
                description="PNG with EICAR inside appended ZIP. Critical test: "
                            "does AV find EICAR when it's inside a ZIP that's "
                            "appended to a PNG?",
                data=result3.data, filename="innocent_image.png",
                expected_contexts=["PNG", "ZIP"],
                expectations={
                    "av": "CRITICAL — AV must detect EICAR inside the ZIP layer. "
                          "If it doesn't, the AV only parsed the PNG layer.",
                    "cdr": "CRITICAL — CDR must sanitize the ZIP layer. "
                          "If the EICAR survives CDR, the tool has a blind spot.",
                    "upload": "Should pass image validators (valid PNG header)",
                    "manual": "Opens as blue square. unzip extracts test.txt with EICAR.",
                },
                metadata={"contains_eicar": True, "eicar_location": "inside ZIP layer"},
            ))

        # Large PNG + small ZIP (coverage asymmetry)
        large_png = make_benign_png(width=256, height=256)
        small_zip_buf = io.BytesIO()
        with zipfile.ZipFile(small_zip_buf, "w") as zf:
            zf.writestr("tiny.txt", "small")
        small_zip = small_zip_buf.getvalue()

        result4 = self._forge_poly.append(large_png, self._png_ctx, small_zip, self._zip_ctx)
        if result4.success:
            artifacts.append(ArtifactSpec(
                id="POLY-004", name="Large PNG + Tiny ZIP (coverage asymmetry)",
                category="polyglot",
                description="Large image with tiny ZIP appended. The ZIP is <1% "
                            "of the file. Tests whether tools inspect trailing bytes.",
                data=result4.data, filename="photo.png",
                expected_contexts=["PNG", "ZIP"],
                expectations={
                    "av": "ZIP layer is tiny — easy to miss in a large file",
                    "cdr": "Does CDR truncate after IEND? If so, ZIP is stripped.",
                    "upload": "Passes size checks, valid PNG",
                    "manual": "Normal image. ZIP extraction reveals tiny.txt",
                },
                forge_details={
                    "png_size": len(large_png),
                    "zip_size": len(small_zip),
                    "zip_percentage": f"{len(small_zip)/len(result4.data)*100:.1f}%",
                },
            ))

        return artifacts

    def _generate_stripped(self) -> list[ArtifactSpec]:
        """Veriduct-style stripped artifacts."""
        print("  [3/6] Stripped (Veriduct)...")
        artifacts = []

        # Strip a PNG
        png = make_benign_png()
        result = self._forge_strip.strip_headers(png, self._png_ctx)
        if result.success:
            artifacts.append(ArtifactSpec(
                id="STRIP-001", name="Stripped PNG (headers zeroed)",
                category="stripped",
                description="PNG with signature and IHDR zeroed. No parser "
                            "should recognize this as PNG anymore.",
                data=result.data, filename="stripped_image.bin",
                expected_contexts=[],  # Should satisfy nothing
                expectations={
                    "av": "Should not detect as any known format",
                    "cdr": "KEY TEST — does CDR pass unknown formats through? "
                          "If yes, stripped content bypasses sanitization.",
                    "upload": "Should fail image validation (no PNG signature)",
                    "manual": "Not openable as image. Binary data.",
                },
                forge_details={
                    "fields_zeroed": len(result.mutations),
                    "original_format": "PNG",
                },
            ))

        # Strip then wrap (round-trip: destroy identity then dress in new one)
        wrapped_back = self._forge_wrap.wrap_as_zip(result.data, "recovered.bin")
        if wrapped_back.success:
            artifacts.append(ArtifactSpec(
                id="STRIP-002", name="Stripped PNG wrapped as ZIP",
                category="stripped",
                description="PNG with identity destroyed, then wrapped in a ZIP "
                            "container. The original PNG bytes are inside but "
                            "no longer recognizable as PNG.",
                data=wrapped_back.data, filename="recovered_archive.zip",
                expected_contexts=["ZIP"],
                expectations={
                    "av": "Looks like a normal ZIP with a .bin inside",
                    "cdr": "ZIP sanitizer runs. Does it inspect the inner .bin?",
                    "upload": "Valid ZIP archive",
                    "manual": "Extracts recovered.bin — which is the stripped PNG",
                },
                metadata={"tunnel_stages": ["PNG", "strip", "wrap_zip"]},
            ))

        # Chunk + XOR (Veriduct fragmentation)
        chunks = self._forge_strip.chunk(png, chunk_size=64, xor_key=0x42)
        if chunks:
            # Pack chunks into a ZIP
            chunk_zip = io.BytesIO()
            with zipfile.ZipFile(chunk_zip, "w") as zf:
                for i, chunk in enumerate(chunks):
                    zf.writestr(f"chunk_{i:04d}.dat", chunk.data)
                zf.writestr("manifest.json", json.dumps({
                    "total_chunks": len(chunks),
                    "chunk_size": 64,
                    "xor_key": "0x42",
                    "original_format": "PNG",
                    "reassembly": "XOR each chunk with 0x42, concatenate in order",
                }))
            artifacts.append(ArtifactSpec(
                id="STRIP-003", name="Chunked + XOR'd PNG in ZIP",
                category="stripped",
                description="PNG split into 64-byte chunks, each XOR'd with 0x42, "
                            "packed into a ZIP. No individual chunk is recognizable. "
                            "Reassembly requires the manifest.",
                data=chunk_zip.getvalue(), filename="fragmented_data.zip",
                expected_contexts=["ZIP"],
                expectations={
                    "av": "Individual chunks are meaningless bytes. No detection.",
                    "cdr": "ZIP is valid. Contents are opaque .dat files.",
                    "upload": "Valid ZIP",
                    "manual": "Extract, XOR each chunk with 0x42, concatenate → original PNG",
                },
                metadata={
                    "num_chunks": len(chunks),
                    "xor_key": "0x42",
                    "reassembly_possible": True,
                },
            ))

        return artifacts

    def _generate_injected(self) -> list[ArtifactSpec]:
        """Residue injection artifacts."""
        print("  [4/6] Residue-injected...")
        artifacts = []

        # Inject marker into PNG residue
        # PNG has minimal residue, so we need a PNG with slack
        # Create a PNG and inject into post-IEND space by appending
        png = make_benign_png()
        marker = make_marker_payload("INJECT")

        # Direct append after IEND (technically not residue but trailing bytes)
        injected_png = png + marker
        png_check = self._png_ctx.satisfies(injected_png)
        if png_check.valid:
            artifacts.append(ArtifactSpec(
                id="INJ-001", name="PNG with trailing marker payload",
                category="injected",
                description="Valid PNG with marker bytes after IEND chunk. "
                            "PNG parsers stop at IEND — trailing bytes are invisible.",
                data=injected_png, filename="tagged_image.png",
                expected_contexts=["PNG"],
                expectations={
                    "av": "PNG is valid, trailing bytes are not scanned by most engines",
                    "cdr": "KEY TEST — does CDR truncate after IEND? "
                          "If not, marker survives sanitization.",
                    "upload": "Passes — valid PNG",
                    "manual": "Opens normally. Hex editor shows marker after IEND.",
                },
                forge_details={
                    "marker_offset": f"{len(png):#x}",
                    "marker_size": len(marker),
                    "png_valid_after": png_check.valid,
                },
            ))

        # Inject EICAR after PNG IEND
        eicar = make_eicar()
        eicar_png = png + eicar
        png_check2 = self._png_ctx.satisfies(eicar_png)
        if png_check2.valid:
            artifacts.append(ArtifactSpec(
                id="INJ-002", name="PNG with EICAR after IEND",
                category="injected",
                description="Valid PNG with EICAR test string appended after IEND. "
                            "CRITICAL: AV should find EICAR even in trailing bytes. "
                            "If it doesn't, AV only parses up to IEND.",
                data=eicar_png, filename="photo_scan.png",
                expected_contexts=["PNG"],
                expectations={
                    "av": "CRITICAL — MUST detect EICAR. If not, AV has a PNG "
                          "trailing-bytes blind spot.",
                    "cdr": "CRITICAL — EICAR must not survive sanitization.",
                    "upload": "Passes as valid PNG",
                    "manual": "Opens as blue square. EICAR visible in hex editor.",
                },
                metadata={"contains_eicar": True, "eicar_location": "after PNG IEND"},
            ))

        # Inject into ZIP comment field
        zip_with_comment = io.BytesIO()
        with zipfile.ZipFile(zip_with_comment, "w") as zf:
            zf.writestr("readme.txt", "Normal file")
            zf.comment = b"Normal archive comment " + marker
        artifacts.append(ArtifactSpec(
            id="INJ-003", name="ZIP with payload in comment field",
            category="injected",
            description="Valid ZIP with marker payload in the archive comment. "
                        "Comments are structural but often unscanned.",
            data=zip_with_comment.getvalue(), filename="commented_archive.zip",
            expected_contexts=["ZIP"],
            expectations={
                "av": "Comment fields rarely scanned",
                "cdr": "Does CDR strip or preserve comments?",
                "upload": "Valid ZIP",
                "manual": "Extracts normally. Comment visible in ZIP tools.",
            },
        ))

        return artifacts

    def _generate_wrapped(self) -> list[ArtifactSpec]:
        """Wrapped artifacts — raw bytes dressed in format containers."""
        print("  [5/6] Wrapped payloads...")
        artifacts = []

        # Wrap random bytes as PNG
        random_payload = os.urandom(256)
        png_wrapped = self._forge_wrap.wrap_as_png(random_payload, width=16)
        if png_wrapped.success:
            artifacts.append(ArtifactSpec(
                id="WRAP-001", name="Random bytes wrapped as PNG",
                category="wrapped",
                description="256 random bytes compressed into a valid PNG's IDAT "
                            "chunk. The PNG is structurally valid but the 'image' "
                            "is noise.",
                data=png_wrapped.data, filename="noise_image.png",
                expected_contexts=["PNG"],
                expectations={
                    "av": "Valid PNG structure — unlikely to flag",
                    "cdr": "Should sanitize as normal PNG. Does the data survive?",
                    "upload": "Passes as image/png",
                    "manual": "Opens as noise/random colored pixels",
                },
            ))

        # Wrap EICAR as ZIP
        eicar = make_eicar()
        zip_wrapped = self._forge_wrap.wrap_as_zip(eicar, "document.txt")
        if zip_wrapped.success:
            artifacts.append(ArtifactSpec(
                id="WRAP-002", name="EICAR wrapped as ZIP",
                category="wrapped",
                description="EICAR string packaged in a ZIP by BIRL's WrapForge. "
                            "Tests if AV scans inside BIRL-generated ZIPs.",
                data=zip_wrapped.data, filename="document_archive.zip",
                expected_contexts=["ZIP"],
                expectations={
                    "av": "MUST detect EICAR inside ZIP. If not, BIRL's ZIP "
                          "container evades inspection.",
                    "cdr": "Must find and handle EICAR",
                    "upload": "Valid ZIP",
                    "manual": "Extracts document.txt containing EICAR",
                },
                metadata={"contains_eicar": True, "eicar_location": "inside ZIP as document.txt"},
            ))

        # Wrap text as PNG (steganographic)
        secret = b"CLASSIFIED: This message is hidden inside pixel data."
        steg_png = self._forge_wrap.wrap_as_png(secret, width=8)
        if steg_png.success:
            artifacts.append(ArtifactSpec(
                id="WRAP-003", name="Text hidden in PNG pixels",
                category="wrapped",
                description="ASCII text encoded as pixel values in a valid PNG. "
                            "Appears as a small noisy image. Text recoverable "
                            "by decompressing IDAT and reading raw bytes.",
                data=steg_png.data, filename="thumbnail.png",
                expected_contexts=["PNG"],
                expectations={
                    "av": "Structurally valid PNG — no detection expected",
                    "cdr": "PNG sanitizer runs. Does it re-encode and destroy payload?",
                    "upload": "Valid image",
                    "manual": "Opens as tiny noisy image. Payload in raw pixel data.",
                },
                metadata={"hidden_content": "ASCII text in pixel values"},
            ))

        return artifacts

    def _generate_layered(self) -> list[ArtifactSpec]:
        """Multi-layer artifacts — combinations of techniques."""
        print("  [6/6] Layered artifacts...")
        artifacts = []

        # Polyglot with EICAR in both layers
        png = make_benign_png()
        eicar = make_eicar()
        eicar_after_png = png + eicar

        eicar_zip = io.BytesIO()
        with zipfile.ZipFile(eicar_zip, "w") as zf:
            zf.writestr("scan_me.txt", eicar.decode("ascii"))
        eicar_zip_bytes = eicar_zip.getvalue()

        double_eicar = png + eicar + eicar_zip_bytes
        png_check = self._png_ctx.satisfies(double_eicar)
        zip_check = self._zip_ctx.satisfies(double_eicar)

        artifacts.append(ArtifactSpec(
            id="LAYER-001", name="Double EICAR: trailing + ZIP layer",
            category="layered",
            description="PNG with EICAR in trailing bytes AND EICAR inside "
                        "an appended ZIP. Tests if AV finds BOTH instances.",
            data=double_eicar, filename="double_check.png",
            expected_contexts=["PNG"] + (["ZIP"] if zip_check.valid else []),
            expectations={
                "av": "CRITICAL — must detect EICAR. Bonus: does it find BOTH? "
                      "One in trailing bytes, one inside ZIP.",
                "cdr": "Must sanitize both layers",
                "upload": "Valid PNG header",
                "manual": "PNG opens. Hex shows trailing EICAR. ZIP extracts EICAR.",
            },
            metadata={
                "contains_eicar": True,
                "eicar_count": 2,
                "eicar_locations": ["PNG trailing bytes", "inside appended ZIP"],
            },
        ))

        # Matryoshka: ZIP containing a polyglot PNG+ZIP
        inner_poly = self._forge_poly.append(png, self._png_ctx, make_benign_zip(), self._zip_ctx)
        if inner_poly.success:
            outer_zip = io.BytesIO()
            with zipfile.ZipFile(outer_zip, "w") as zf:
                zf.writestr("image.png", inner_poly.data)
                zf.writestr("readme.txt", "This archive contains an image.")
            artifacts.append(ArtifactSpec(
                id="LAYER-002", name="Matryoshka: ZIP(polyglot PNG+ZIP)",
                category="layered",
                description="A ZIP archive containing a PNG+ZIP polyglot. "
                            "The inner 'image.png' is itself an archive. "
                            "Tests recursive inspection depth.",
                data=outer_zip.getvalue(), filename="documents.zip",
                expected_contexts=["ZIP"],
                expectations={
                    "av": "Must inspect inside ZIP. Must then detect inner "
                          "file is a polyglot. Tests recursion depth.",
                    "cdr": "Does CDR recurse into ZIP contents and sanitize "
                          "the inner polyglot?",
                    "upload": "Valid ZIP",
                    "manual": "Extract image.png → valid PNG + valid ZIP",
                },
                metadata={"nesting_depth": 2},
            ))

        return artifacts


# ============================================================================
# Verification
# ============================================================================

class HarnessVerifier:
    """Verify generated artifacts against BIRL's own parsers."""

    def __init__(self):
        self._world = World()
        if PRODUCTION:
            self._world.register(PEProductionContext())
            self._world.register(ELFProductionContext())
            self._world.register(ZIPProductionContext())
            self._world.register(PNGProductionContext())
            self._world.register(x86ProductionContext(mode="64"))
        else:
            self._world.register(PE_Context())
            self._world.register(ELF_Context())
            self._world.register(ZIP_Context())
            self._world.register(PNG_Context())
            self._world.register(x86_Context())
        self._world.register(UTF8_Context())
        self._world.build_graph()

    def verify(self, artifact_dir: str) -> dict:
        """Verify all artifacts in a directory."""
        manifest_path = Path(artifact_dir) / "manifest.json"
        if not manifest_path.exists():
            print(f"No manifest.json in {artifact_dir}")
            return {}

        manifest = json.loads(manifest_path.read_text())
        results = {}

        for entry in manifest["artifacts"]:
            artifact_path = Path(artifact_dir) / entry["filename"]
            if not artifact_path.exists():
                results[entry["id"]] = {"status": "MISSING"}
                continue

            data = artifact_path.read_bytes()
            result = self._verify_single(data, entry)
            results[entry["id"]] = result

        return results

    def _verify_single(self, data: bytes, spec: dict) -> dict:
        """Verify a single artifact."""
        result = {
            "id": spec["id"],
            "name": spec["name"],
            "hash_match": hashlib.sha256(data).hexdigest() == spec["sha256"],
            "size_match": len(data) == spec["size"],
            "contexts_detected": [],
            "expected_contexts_satisfied": False,
        }

        identities = self._world.identify(data)
        detected = [name for name, vt in identities if vt.valid]
        result["contexts_detected"] = detected

        expected = set(spec.get("expected_contexts", []))
        result["expected_contexts_satisfied"] = expected.issubset(set(detected))

        # Check for EICAR presence
        if spec.get("metadata", {}).get("contains_eicar"):
            eicar_sig = b"EICAR-STANDARD-ANTIVIRUS-TEST-FILE"
            result["eicar_present"] = eicar_sig in data
            # Also check inside ZIP
            try:
                zf = zipfile.ZipFile(io.BytesIO(data))
                for name in zf.namelist():
                    content = zf.read(name)
                    if eicar_sig in content:
                        result["eicar_in_zip"] = True
                        break
                zf.close()
            except Exception:
                pass

        return result


# ============================================================================
# Report Generator
# ============================================================================

def generate_report(artifact_dir: str, results: dict) -> str:
    """Generate a human-readable test report."""
    manifest = json.loads((Path(artifact_dir) / "manifest.json").read_text())

    lines = [
        "=" * 70,
        "  BIRL TEST HARNESS — ARTIFACT REPORT",
        f"  Generated: {manifest.get('generated_at', '?')}",
        f"  Artifacts: {manifest.get('total_artifacts', '?')}",
        "=" * 70,
        "",
        "INSTRUCTIONS:",
        "  1. Submit each artifact to your target tool (AV, CDR, upload validator)",
        "  2. Record the result in the 'actual' column below",
        "  3. Compare with 'expected' to identify blind spots",
        "",
    ]

    for entry in manifest["artifacts"]:
        aid = entry["id"]
        verification = results.get(aid, {})

        lines.append("-" * 70)
        lines.append(f"  {aid}: {entry['name']}")
        lines.append(f"  File: {entry['filename']}  ({entry['size']} bytes)")
        lines.append(f"  SHA256: {entry['sha256']}")
        lines.append(f"  Category: {entry['category']}")
        lines.append(f"  {entry['description']}")
        lines.append("")

        v_status = "OK" if verification.get("expected_contexts_satisfied") else "CHECK"
        lines.append(f"  Self-check: {v_status}  "
                     f"Detected as: {verification.get('contexts_detected', [])}")
        lines.append("")

        lines.append("  EXPECTED RESULTS:")
        for tool, expected in entry.get("expectations", {}).items():
            lines.append(f"    {tool.upper():8s}: {expected}")
            lines.append(f"    {'':8s}  ACTUAL: ____________________")

        if entry.get("metadata", {}).get("contains_eicar"):
            lines.append("")
            lines.append("  ⚠ CONTAINS EICAR — failure to detect is a confirmed blind spot")

        lines.append("")

    lines.append("=" * 70)
    lines.append("  END OF REPORT")
    lines.append("=" * 70)

    return "\n".join(lines)


# ============================================================================
# CLI
# ============================================================================

def cmd_generate(args):
    """Generate the full artifact battery."""
    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    generator = HarnessGenerator()
    artifacts = generator.generate_all()

    print(f"\nWriting {len(artifacts)} artifacts to {output_dir}/\n")

    manifest = {
        "generated_at": datetime.now().isoformat(),
        "generator": "BIRL Test Harness v1.0",
        "total_artifacts": len(artifacts),
        "artifacts": [],
    }

    for artifact in artifacts:
        # Write artifact file
        filepath = output_dir / artifact.filename
        filepath.write_bytes(artifact.data)

        manifest["artifacts"].append(artifact.to_manifest())
        print(f"  {artifact.id:12s}  {artifact.filename:35s}  {len(artifact.data):>8,} bytes  {artifact.name}")

    # Write manifest
    manifest_path = output_dir / "manifest.json"
    manifest_path.write_text(json.dumps(manifest, indent=2))

    # Self-verify
    print(f"\nSelf-verifying...")
    verifier = HarnessVerifier()
    results = verifier.verify(str(output_dir))

    all_ok = all(r.get("expected_contexts_satisfied", False) for r in results.values())
    passed = sum(1 for r in results.values() if r.get("expected_contexts_satisfied"))
    print(f"  {passed}/{len(results)} artifacts verified OK")

    # Generate report
    report = generate_report(str(output_dir), results)
    report_path = output_dir / "REPORT.txt"
    report_path.write_text(report)
    print(f"\nReport: {report_path}")
    print(f"Manifest: {manifest_path}")
    print(f"\nDone. Submit artifacts to your target tools and fill in the REPORT.txt.")


def cmd_verify(args):
    """Verify artifacts in a directory."""
    verifier = HarnessVerifier()
    results = verifier.verify(args.artifact_dir)

    for aid, result in results.items():
        status = "✓" if result.get("expected_contexts_satisfied") else "✗"
        contexts = result.get("contexts_detected", [])
        print(f"  {status} {aid}: detected={contexts}")


def cmd_report(args):
    """Regenerate report for an artifact directory."""
    verifier = HarnessVerifier()
    results = verifier.verify(args.artifact_dir)
    report = generate_report(args.artifact_dir, results)
    print(report)


def main():
    parser = argparse.ArgumentParser(
        prog="birl-harness",
        description="BIRL Test Harness — Generate and verify security test artifacts",
    )

    sub = parser.add_subparsers(dest="command")

    p = sub.add_parser("generate", help="Generate the full artifact battery")
    p.add_argument("--output-dir", default="./harness_output", help="Output directory")

    p = sub.add_parser("verify", help="Verify artifacts against BIRL parsers")
    p.add_argument("artifact_dir", help="Directory containing artifacts + manifest")

    p = sub.add_parser("report", help="Generate/view test report")
    p.add_argument("artifact_dir", help="Directory containing artifacts + manifest")

    args = parser.parse_args()

    if not args.command:
        parser.print_help()
        return

    if args.command == "generate":
        cmd_generate(args)
    elif args.command == "verify":
        cmd_verify(args)
    elif args.command == "report":
        cmd_report(args)


if __name__ == "__main__":
    main()
